# Bag of Visual Words (BoVW) model with SIFT features and a Convolutional Neural Network (CNN) for object recognition on a subset of the Caltech256 dataset
This project investigates the performance of traditional computer vision and deep learning approaches for object recognition on a subset of the Caltech256 dataset, comprising six classes: airplanes-101, motorbikes-101, faces-easy-101, t-shirt, billiards, and horse. A Bag of Visual Words (BoVW) model, utilizing SIFT features and optimized with a vocabulary size of 200, was compared against a Convolutional Neural Network (CNN) with two convolutional layers, filters (16, 32), a kernel size of 5, and a dropout rate of 0.25, trained using the Adam optimizer. The dataset, augmented to 6000 grayscale images via rotations, was split into an 80/20 train-test ratio. The BoVW approach, tested with SVM, Naive Bayes, and kNN classifiers, achieved a best accuracy of 31% using SVM, with significant misclassifications for complex classes like motorbikes-101 (3.5% accuracy) due to its inability to capture spatial relationships. In contrast, the CNN, after systematic hyperparameter optimization, attained a test accuracy of 88.00% (error rate 12.00%), with precision, recall, and F1-scores of 0.8879, 0.8800, and 0.8822, respectively, demonstrating its superior ability to learn hierarchical features. The comparison highlights the CNN’s effectiveness for the dataset, while the BoVW model’s limitations underscore the need for spatial context in traditional methods, offering insights into their applicability in robotics vision tasks.
